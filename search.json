[
  {
    "objectID": "input_json.html",
    "href": "input_json.html",
    "title": "Read an input JSON statement",
    "section": "",
    "text": "The libraries used to import the data:\nAs an example, in this package we provide a json file containing a statement and all its related metadata\n\njson_file = '../example_single_statement.json'\n\n\nLoad an xAPI statement\nLet’s start parsing the json file\n\nsource\n\n\nload_statement\n\n load_statement (json_file:str)\n\nLoad a json from file and store the information in a Python dictionary object. If the file does not exist, returns an empty dict and print an error message\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\njson_file\nstr\nFilename of the json containing the statement\n\n\nReturns\ndict\nA dictionary representing the statement structure\n\n\n\n\nmy_statement = load_statement(json_file)\n\n\nsource\n\n\npretty_print_statement\n\n pretty_print_statement (statement:dict, indent:int=4)\n\nDisplays the content of the statement in a human readable format\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstatement\ndict\n\nthe statement dict imported from JSON\n\n\nindent\nint\n4\nindentation used when printing\n\n\nReturns\nNone\n\n\n\n\n\n\nsample_json = json.loads('[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]')\npretty_print_statement(sample_json, indent=2)\n\n[\n  \"foo\",\n  {\n    \"bar\": [\n      \"baz\",\n      null,\n      1.0,\n      2\n    ]\n  }\n]\n\n\n\nsource\n\n\nget_value\n\n get_value (statement:dict, key:str)\n\nReturn the value associated to the specified key in the statement dictionary. If the key does not exist, returns None\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nkey\nstr\nThe key we are interested in\n\n\nReturns\ntyping.Union[str, dict, typing.List, NoneType]\nThe value associated to the key in the statement\n\n\n\n\ntest_eq(get_value(my_statement, \"not_a_key\"), None)\ntest_eq(get_value(my_statement, \"stored\"), \"2022-09-30T13:34:35.959Z\")\n\n\nExtract statement data\nThe following methids are used to extract the actor, verb and object information, which represents the core information provided in each statement, as well as the version statement\n\nsource\n\n\n\nget_actor\n\n get_actor (statement:dict)\n\nExtract the actor information from the statement\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ndict\ndictionary containing actor information\n\n\n\n\ntest_actor = {\n      \"objectType\": \"Agent\",\n      \"name\": \"1s1116\",\n      \"mbox\": \"mailto:student@app.com\"\n    }\nactor = get_actor(my_statement)\ntest_eq(actor[\"objectType\"], test_actor[\"objectType\"])\ntest_eq(actor[\"name\"], test_actor[\"name\"])\ntest_eq(actor[\"mbox\"], test_actor[\"mbox\"])\n\n\nsource\n\n\nget_actor_name\n\n get_actor_name (statement:dict)\n\nQuick access to the name field of the actor, as it is the most relevant information\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nname of the actor\n\n\n\n\ntest_eq(get_actor_name(my_statement), \"1s1116\")\n\n\nsource\n\n\nget_verb\n\n get_verb (statement:dict)\n\nExtract the verb information from the statement\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ndict\ndictionary containing verb information\n\n\n\n\ntest_verb = {\n      \"id\": \"http://id.tincanapi.com/verb/selected/\",\n      \"display\": {\n        \"en-US\": \"Selected\"\n      }\n}\nverb = get_verb(my_statement)\ntest_eq(verb[\"id\"], test_verb[\"id\"])\ntest_eq(verb[\"display\"][\"en-US\"], test_verb[\"display\"][\"en-US\"])\n\n\nsource\n\n\nget_verb_str\n\n get_verb_str (statement:dict)\n\nQuick access to the display field of the verb, as it is the most relevant information\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nthe displayed verb\n\n\n\n\ntest_eq(get_verb_str(my_statement), \"Selected\")\n\n\nsource\n\n\nget_object\n\n get_object (statement:dict)\n\nExtract the object information from the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ndict\ndictionary containing object information\n\n\n\n\ntest_obj = {\n      \"objectType\": \"Activity\",\n      \"id\": \"http://example.com/activities/student-lesson\",\n      \"definition\": {\n        \"name\": {\n          \"en-US\": \"Lesson\"\n        },\n        \"description\": {\n          \"en-US\": \"Level 1 Module8 started\"\n        }\n      }\n}\nobj = get_object(my_statement)\ntest_eq(obj[\"id\"], test_obj[\"id\"])\ntest_eq(obj[\"objectType\"], test_obj[\"objectType\"])\ntest_eq(obj[\"definition\"][\"name\"][\"en-US\"], test_obj[\"definition\"][\"name\"][\"en-US\"])\ntest_eq(obj[\"definition\"][\"description\"][\"en-US\"], test_obj[\"definition\"][\"description\"][\"en-US\"])\n\n\nsource\n\n\nget_object_definition\n\n get_object_definition (statement:dict)\n\nQuick access to the object definition\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nthe object definition\n\n\n\n\ntest_eq(get_object_definition(my_statement), \"Lesson\")\n\n\nsource\n\n\nget_object_description\n\n get_object_description (statement:dict)\n\nQuick access to the object description\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nthe object description\n\n\n\n\ntest_eq(get_object_description(my_statement), \"Level 1 Module8 started\")\n\n\nExtract the metadata information\nThe following methods are used to extract the metadata fields we may be interested in\n\nGet general metadata information\n\nsource\n\n\n\n\nget_stored\n\n get_stored (statement:dict)\n\nExtract the date and time information of when the statement was stored in the database\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ndatetime\ndatetime object representing the time the statement was stored in the database\n\n\n\n\nmy_date = datetime.strptime(\"2022-09-30T13:34:35.959Z\", \"%Y-%m-%dT%H:%M:%S.%f%z\")\ntest_eq(get_stored(my_statement), my_date)\n\n\nsource\n\n\nget_timestamp\n\n get_timestamp (statement:dict)\n\nExtract the date and time information of when the statement was created\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ndatetime\ndatetime object representing the time the statement was generated\n\n\n\n\nmy_ts = datetime.strptime(\"2022-09-30T13:34:35.959Z\", \"%Y-%m-%dT%H:%M:%S.%f%z\")\ntest_eq(get_timestamp(my_statement), my_date)\n\n\nsource\n\n\nget_time_diff\n\n get_time_diff (statement:dict)\n\nCompute the time difference between when a statement was sent and when it was stored in the database\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntimedelta\nTime difference between when the statement was sent and when it was stored\n\n\n\n\ntest_eq(get_time_diff(my_statement), timedelta()) # In our example statement the timestamps are the same\n\n\nGet Boolean metadata information\nThese methods return the metadata providing boolean information related to the statement\n\nsource\n\n\n\nis_active\n\n is_active (statement:dict)\n\nExtract the Active field from the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nbool\nBoolean representive whether active or not\n\n\n\n\ntest_eq(is_active(my_statement), True)\n\n\nsource\n\n\nis_voided\n\n is_voided (statement:dict)\n\nExtract the Active field from the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nbool\nBoolean representive whether statement is voided or not\n\n\n\n\ntest_eq(is_voided(my_statement), False)\n\n\nsource\n\n\nhas_generated_id\n\n has_generated_id (statement:dict)\n\nExtract the Active field from the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nbool\nBoolean representive whether statement has generated id\n\n\n\n\ntest_eq(has_generated_id(my_statement), False)\n\n\nGet ID metadata information\nThese methods return the metadata providing ID information\n\nsource\n\n\n\nget_client\n\n get_client (statement:dict)\n\nExtract the client field from the statement\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nID of the client\n\n\n\n\ntest_eq(get_client(my_statement), \"60ffcf8d448b2d059a63e3c4\")\n\n\nsource\n\n\nget_LRS\n\n get_LRS (statement:dict)\n\nExtract the Learning Record Store ID field from the statement\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nID of the Learning Record Store\n\n\n\n\ntest_eq(get_LRS(my_statement), \"60ffcf8d448b2d059a63e3c3\")\n\n\nsource\n\n\nget_id\n\n get_id (statement:dict)\n\nExtract the ID field from the statement\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nID of the statement\n\n\n\n\ntest_eq(get_id(my_statement), \"6336f06c6ce79d05ebef40a7\")\n\n\nsource\n\n\nget_persona_id\n\n get_persona_id (statement:dict)\n\nExtract the persona identifier\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nid of the persona associated to the statement\n\n\n\n\ntest_eq(get_persona_id(my_statement), \"6103e17eaed02c30c695bffb\")\n\n\nsource\n\n\nget_organisation\n\n get_organisation (statement:dict)\n\nExtract the persona identifier\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nid of the organization to the statement\n\n\n\n\ntest_eq(get_organisation(my_statement), \"60faab70448b2d059a63e375\")\n\n\nsource\n\n\nget_hash\n\n get_hash (statement:dict)\n\nExtract the hash\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\nstr\nhash of the statement\n\n\n\n\ntest_eq(get_hash(my_statement), \"3268dd76c35a6077796979e0613654ecf449c46e\")\n\n\nGet queues metadata information\nThese methods return the metadata related to the queues information in the statement\n\nsource\n\n\n\nget_completed_fw_queues\n\n get_completed_fw_queues (statement:dict)\n\nExtract the List of completed forwarding queues in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of completed forwarding queues in the statement\n\n\n\n\ntest_eq(get_completed_fw_queues(my_statement), list())\n\n\nsource\n\n\nget_failed_fw_log\n\n get_failed_fw_log (statement:dict)\n\nExtract the List of failed forwarding log messages in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of failed forwarding log messages in the statement\n\n\n\n\ntest_eq(get_failed_fw_log(my_statement), list())\n\n\nsource\n\n\nget_completed_queues\n\n get_completed_queues (statement:dict)\n\nExtract the List of completed queues in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of completed queues in the statement\n\n\n\n\nCOMPL_QS = [\"STATEMENT_FORWARDING_QUEUE\", \"STATEMENT_PERSON_QUEUE\", \"STATEMENT_QUERYBUILDERCACHE_QUEUE\"]\ntest_eq(get_completed_queues(my_statement), COMPL_QS)\n\n\nsource\n\n\nget_completed_queues\n\n get_completed_queues (statement:dict)\n\nExtract the List of completed queues in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of completed queues in the statement\n\n\n\n\ntest_eq(get_completed_fw_queues(my_statement), list())\n\n\nsource\n\n\nget_dead_forwarding_queues\n\n get_dead_forwarding_queues (statement:dict)\n\nExtract the List of dead forwarding queues in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of dead forwarding queues in the statement\n\n\n\n\ntest_eq(get_dead_forwarding_queues(my_statement), list())\n\n\nsource\n\n\nget_pending_forwarding_queues\n\n get_pending_forwarding_queues (statement:dict)\n\nExtract the List of pending forwarding queues in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of completed queues in the statement\n\n\n\n\ntest_eq(get_pending_forwarding_queues(my_statement), list())\n\n\nsource\n\n\nget_processing_queues\n\n get_processing_queues (statement:dict)\n\nExtract the List of processing queues in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of processing queues in the statement\n\n\n\n\ntest_eq(get_processing_queues(my_statement), list())\n\n\nsource\n\n\nget_registrations\n\n get_registrations (statement:dict)\n\nExtract the List of registrations in the statement\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstatement\ndict\nOur xAPI statement imported from JSON\n\n\nReturns\ntyping.List\nList of registrations in the statement\n\n\n\n\ntest_eq(get_registrations(my_statement), list())"
  },
  {
    "objectID": "input_csv.html",
    "href": "input_csv.html",
    "title": "Read xAPI statements stored in a csv file",
    "section": "",
    "text": "The libraries used:\nAs an example, in this package we provide three csv files containing a few hundreds of xAPI statements.\n\ncsv_files = ['../example_statements_1.csv', '../example_statements_2.csv', '../example_statements_3.csv', \n            '../example_statements_4.csv']\n\n\nLoad statements from file\nLet’s start by reading the csv file. This first example uses ; as a delimiter, but usually it’s a ,. We will shortly define a function that takes care of all the differences between xAPI statements datasets.\n\nif Path(csv_files[0]).exists():\n    statements = pd.read_csv(csv_files[0], index_col=None, delimiter=';').reset_index(drop=True) \nelse:\n    print(\"The specified file does not exist. Creating an empty DataFrame...\")\n    statements = pd.DataFrame()\nstatements.head()\n\n\n\n\n\n\n\n\ntimestamp\nlrs_id\nactor name\nverb id\nverb display\nobject id\nobject name\nresult\n\n\n\n\n0\n2022-08-02T14:44:34.4429540Z\n6148511b448b2d059a63e424\nAAA430802\nhttp://activitystrea.ms/schema/1.0/start\n{'en-us': 'started'}\nhttps://wekit-community.org/stepID=TS-ef86ff46...\n{'en-us': 'Action Step 3'}\nNaN\n\n\n1\n2022-08-02T14:44:34.0702380Z\n6148511b448b2d059a63e424\nAAA430802\nhttp://id.tincanapi.com/verb/viewed\n{'en-us': 'viewed'}\nhttp://MirageXR_Image_133039249801494090.jpg\nNaN\nNaN\n\n\n2\n2022-08-02T14:44:34.0626310Z\n6148511b448b2d059a63e424\nAAA430802\nhttp://activitystrea.ms/schema/1.0/listen\n{'en-us': 'listened_to'}\nhttp://characterinfo/TS-ef86ff46-70b6-472a-93d...\nNaN\nNaN\n\n\n3\n2022-08-02T14:44:34.0477250Z\n6148511b448b2d059a63e424\nAAA430802\nhttps://wekit-community.org/verb/met\n{'en-us': 'met'}\nresources:// char:Woman_C\n{'en-us': 'char:Woman_C'}\nNaN\n\n\n4\n2022-08-02T14:43:28.0360420Z\n6148511b448b2d059a63e424\nAAA430802\nhttp://activitystrea.ms/schema/1.0/start\n{'en-us': 'started'}\nhttps://wekit-community.org/stepID=TS-a5780c27...\n{'en-us': 'Action Step 2'}\nNaN\n\n\n\n\n\n\n\nIdeally we want to have a more readable version of the content. We want to have three columns named actor, verb and object that contain the statement information in a readable format. We also would like to have the timestamp information as a datetime object, and we do not care about IDs, as they are usually random strings which are not needed in the data analysis. The function import_csv does all of this for us.\n\nsource\n\n\nimport_csv\n\n import_csv (csv_file:Union[str,pathlib.Path], index_col:int=0,\n             delimiter:str=',', quotechar:str='\"')\n\nReads a csv file and perform some processing to make the data easier to read as well as easier to process afterwards. Returns a pandas Dataframe\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncsv_file\ntyping.Union[str, pathlib.Path]\n\nFilename of the csv with the data\n\n\nindex_col\nint\n0\nThe index column\n\n\ndelimiter\nstr\n,\nthe column delimiter\n\n\nquotechar\nstr\n”\nQuoting char. Ignore delimiter between this character\n\n\nReturns\nDataFrame\n\nThe imported dataframe with all the xAPI statements\n\n\n\nLet’s use the function we just defined to reload the dataframe and check that it works as expected:\n\nstatements = import_csv(csv_files[0], index_col=None, delimiter=';') \nstatements.head()\n\n\n\n\n\n\n\n\ntimestamp\nactor\nresult\nverb\nobject\n\n\n\n\n0\n2022-08-02T14:44:34.4429540Z\nAAA430802\nNaN\nstarted\nAction Step 3\n\n\n1\n2022-08-02T14:44:34.0702380Z\nAAA430802\nNaN\nviewed\nNone\n\n\n2\n2022-08-02T14:44:34.0626310Z\nAAA430802\nNaN\nlistened_to\nNone\n\n\n3\n2022-08-02T14:44:34.0477250Z\nAAA430802\nNaN\nmet\nchar:Woman_C\n\n\n4\n2022-08-02T14:43:28.0360420Z\nAAA430802\nNaN\nstarted\nAction Step 2\n\n\n\n\n\n\n\nJust to make sure, let’s repeat the process for the other files. In some cases the function can be called with slightly different arguments, depending on the specific format of the file. For example, for the next file we specify a quote character and use a different delimiter\n\nstatements = import_csv(csv_files[1], index_col=None, delimiter=',', quotechar='\"') \nstatements.head()\n\n\n\n\n\n\n\n\ntimestamp\nactor\nobject description\nresult\nverb\nobject\n\n\n\n\n0\n2022-06-24T08:46:28.169Z\n336078\n{'en-US': 'Pause/Leave app'}\n{\"completion\":true}\npause app\nPause\n\n\n1\n2022-06-24T08:42:38.636Z\n336078\n{'en-US': 'Return to app'}\n{\"completion\":true}\nReturn to app\nReturn\n\n\n2\n2022-06-24T08:42:30.775Z\n336078\n{'en-US': 'Pause/Leave app'}\n{\"completion\":true}\npause app\nPause\n\n\n3\n2022-06-24T08:42:10.209Z\n336078\n{'en-US': 'Account 1s1115 logged in'}\n{\"completion\":true}\nLog In\nAccess app\n\n\n4\n2022-06-23T09:14:19.815Z\n370445\n{'en-US': 'Pause/Leave app'}\n{\"completion\":true}\npause app\nPause\n\n\n\n\n\n\n\nAnother file has additional columns that can be interesting, such as language\n\nstatements = import_csv(csv_files[2], index_col=None, delimiter=',') \nstatements.head()\n\n\n\n\n\n\n\n\ntimestamp\nactor\nresult\nlanguage\nverb\nobject\n\n\n\n\n0\n2022-07-14T10:58:11.295Z\nB78BFDBA-9CA9-4787-B2D4-7BD43F042135\n{\"score\":{\"raw\":0}}\nRomanian\nexit\nmain_menu\n\n\n1\n2022-07-14T10:57:56.684Z\nB78BFDBA-9CA9-4787-B2D4-7BD43F042135\n{\"score\":{\"raw\":0}}\nRomanian\nlaunched\nscene_game\n\n\n2\n2022-07-14T10:57:50.804Z\nB78BFDBA-9CA9-4787-B2D4-7BD43F042135\n{\"score\":{\"raw\":0}}\nRomanian\nexit\nmain_menu\n\n\n3\n2022-07-14T10:57:42.154Z\nB78BFDBA-9CA9-4787-B2D4-7BD43F042135\n{\"score\":{\"raw\":0}}\nRomanian\nlaunched\nscene_maths_game\n\n\n4\n2022-07-14T10:57:28.866Z\nB78BFDBA-9CA9-4787-B2D4-7BD43F042135\n{\"score\":{\"raw\":0}}\nRomanian\nlaunched\nscene_tests\n\n\n\n\n\n\n\nFinally, some files (like the one we open now) have an index representing the number of statement in the first column, so we specify an index_col\n\nstatements = import_csv(csv_files[3], index_col=0, delimiter=',') \nstatements.head()\n\n\n\n\n\n\n\n\ntimestamp\nstored\nactor\nverb\nobject\nresult\n\n\n\n\n0\n2023-03-10 11:45:09.638000+00:00\n2023-03-10T11:45:09.638Z\nTeacher\nLogged In\nSalesianos\nNaN\n\n\n1\n2023-03-10 11:52:00.020000+00:00\n2023-03-10T11:52:00.020Z\nPC006\nLogged In\nSalesianos\nNaN\n\n\n2\n2023-03-10 11:52:04.063000+00:00\n2023-03-10T11:52:04.063Z\nPC008\nLogged In\nSalesianos\nNaN\n\n\n3\n2023-03-10 11:52:05.177000+00:00\n2023-03-10T11:52:05.177Z\nTablet1\nLogged In\nSalesianos\n{\"score\":{\"raw\":0}}\n\n\n4\n2023-03-10 11:52:05.679000+00:00\n2023-03-10T11:52:05.679Z\nPC004\nLogged In\nSalesianos\nNaN\n\n\n\n\n\n\n\nThe three most important columns are actor, verb and object, which create a sentence-like structure. We can see the actions that the app registers from the verb column.\n\nsource\n\n\nget_all_verbs\n\n get_all_verbs (df:pandas.core.frame.DataFrame)\n\nReturns a set with all verbs in the dataset\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\nReturns\ntyping.Set\nSet containing all the verbs occurring in the dataset\n\n\n\n\ntest_verbs = {'Logged In', 'Placed', 'Swiped', 'Asked', 'Started', 'Logged Out',\n       'Accepted', 'Set Turn', 'Suggested', 'Ran Out', 'Sent', 'Checked',\n       'Assigned', 'Canceled', 'Ended'}\ntest_eq(get_all_verbs(statements), test_verbs)\n\nWe provide similar functions for actors and objects\n\nsource\n\n\nget_all_actors\n\n get_all_actors (df:pandas.core.frame.DataFrame)\n\nReturns a set with all actors in the dataset\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\nReturns\ntyping.Set\nSet containing all the actors occurring in the dataset\n\n\n\n\ntest_actors = {'Teacher', 'PC006', 'PC008', 'Tablet1', 'PC004', 'PC009', 'PC007', 'PC003', 'Iphone 1',\n       'PC005', 'iPad2', 'Tablet 2', 'Android1', 'Android2', 'iPad1', 'PC002', 'Android4', 'Android3',\n       'iphone 1', 'iPhone 1', 'Ipad1', 'Tablet1 ', 'Ipad2'}\ntest_eq(get_all_actors(statements), test_actors)\n\n\nsource\n\n\nget_all_objects\n\n get_all_objects (df:pandas.core.frame.DataFrame)\n\nReturns a set with all objects in the dataset\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\nReturns\ntyping.Set\nSet containing all the objects occurring in the dataset\n\n\n\nThe list of unique objects is quite big, so we will not print it in this example.\nAs the actor values are usually associated to a user input (for example the username provided when starting the app), it makes sense to clean the values as to avoid that User1, user1 and user 1 are trated as the same user. The following functions allow to do just that, on the desired columns.\n\nsource\n\n\nremove_whitespaces\n\n remove_whitespaces (df:pandas.core.frame.DataFrame, cols:List)\n\nRemoves whitespaces from the specified columns in the dataframe.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\ncols\ntyping.List\nthe columns on which whitespaces should be removed\n\n\nReturns\nDataFrame\nThe dataframe after applying the function\n\n\n\n\nsource\n\n\nto_lowercase\n\n to_lowercase (df:pandas.core.frame.DataFrame, cols:List)\n\nConverts to lowercase the elements in the specified columns. The function only applies to columnns whose type is str\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\ncols\ntyping.List\nthe columns whose content should be made lowercase\n\n\nReturns\nDataFrame\nThe dataframe after applying the function\n\n\n\n\ntest_actors = {'teacher', 'pc006', 'pc008', 'tablet1', 'pc004', 'pc009', 'pc007', 'pc003', 'iphone1',\n               'pc005', 'ipad2', 'tablet2', 'android1', 'android2', 'ipad1', 'pc002', 'android4', 'android3'}\ndf = remove_whitespaces(statements, [\"actor\"])\ndf2 = to_lowercase(df, [\"actor\"])\ntest_eq(get_all_actors(df2), test_actors)\n\nWe may also be interested in removing specific rows from the dataset, for examples the ones associated to an actor that opted out of the intervention, or for verbs we do not care about. This could be the case for example for verbs like Log In or Log out, which provides information about when a user starts and stops the app, but may be not relevant in case our analysis is only about the interactions from within the app.\n\nsource\n\n\nremove_actors\n\n remove_actors (df:pandas.core.frame.DataFrame, cols:List)\n\nRemoves from the dataframe all the rows whose actor is in the specified list\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\ncols\ntyping.List\nthe list of actors to remove\n\n\nReturns\nDataFrame\nThe dataframe with the specified actors removed\n\n\n\n\nstatements = import_csv(csv_files[3], index_col=0, delimiter=',') \ntest_actors = {'Teacher', 'PC006', 'PC008', 'Tablet1', 'PC004', 'PC009', 'PC007', 'PC003', 'Iphone 1',\n       'PC005', 'iPad2', 'Tablet 2', 'Android1', 'Android2'}\ntest_df = remove_actors(statements, ['iPad1', 'PC002', 'Android4', 'Android3',\n       'iphone 1', 'iPhone 1', 'Ipad1', 'Tablet1 ', 'Ipad2'])\ntest_eq(get_all_actors(test_df), test_actors)\n\n\nsource\n\n\nremove_verbs\n\n remove_verbs (df:pandas.core.frame.DataFrame, cols:List)\n\nRemoves from the dataframe all the rows whose actor is in the specified list\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\ncols\ntyping.List\nthe list of verbs to remove\n\n\nReturns\nDataFrame\nThe dataframe with the specified verbs removed\n\n\n\n\ntest_verbs = {'Placed', 'Swiped', 'Asked', 'Started', 'Accepted', 'Set Turn', 'Suggested', 'Ran Out',\n              'Sent', 'Checked', 'Assigned', 'Canceled', 'Ended'}\ntest_df = remove_verbs(statements, [\"Logged In\", \"Logged Out\"])\ntest_eq(get_all_verbs(test_df), test_verbs)\n\n\nxAPI statements analysis\nHere we present some functions that are typically applied when analysing xAPI statements data. For this, we will use a clean version of the statements dataset, where some of the functions described above has been applied\n\nstatements = remove_whitespaces(statements, [\"actor\"])\nstatements = to_lowercase(statements, [\"actor\"])\nstatements = remove_verbs(statements, [\"Logged In\", \"Logged Out\"])\nstatements = remove_actors(statements, [\"android3\"])\nstatements.head(5)\n\n\n\n\n\n\n\n\ntimestamp\nstored\nactor\nverb\nobject\nresult\n\n\n\n\n14\n2023-03-10 11:52:18.277000+00:00\n2023-03-10T11:52:18.277Z\niphone1\nPlaced\nEarth\n{\"score\":{\"raw\":0}}\n\n\n15\n2023-03-10 11:52:18.847000+00:00\n2023-03-10T11:52:18.847Z\niphone1\nSwiped\nLeft\n{\"score\":{\"raw\":0}}\n\n\n18\n2023-03-10 11:52:29.001000+00:00\n2023-03-10T11:52:29.001Z\niphone1\nPlaced\nEarth\n{\"score\":{\"raw\":0}}\n\n\n19\n2023-03-10 11:52:29.094000+00:00\n2023-03-10T11:52:29.094Z\nandroid2\nPlaced\nEarth\n{\"score\":{\"raw\":0}}\n\n\n20\n2023-03-10 11:52:29.194000+00:00\n2023-03-10T11:52:29.194Z\niphone1\nSwiped\nRight\n{\"score\":{\"raw\":0}}\n\n\n\n\n\n\n\nA typical check is to evaluate how many interactions are provided by each actor:\n\nsource\n\n\n\ncount_interactions\n\n count_interactions (df:pandas.core.frame.DataFrame)\n\nCreates a new dataframe counting the total number of statements associated to each actor\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\nReturns\nDataFrame\nA dataframe with the number of interactions of each actor\n\n\n\nOn our toy dataset, it looks like this:\n\ninteractions =  count_interactions(statements)\ninteractions\n\n\n\n\n\n\n\n\nactor\ncount\n\n\n\n\n0\npc009\n6\n\n\n1\npc006\n13\n\n\n2\npc008\n19\n\n\n3\npc002\n21\n\n\n4\npc004\n32\n\n\n5\npc007\n42\n\n\n6\npc003\n43\n\n\n7\niphone1\n86\n\n\n8\nipad1\n87\n\n\n9\nandroid4\n106\n\n\n10\nteacher\n112\n\n\n11\nandroid1\n119\n\n\n12\ntablet1\n133\n\n\n13\nipad2\n140\n\n\n14\ntablet2\n145\n\n\n15\nandroid2\n147\n\n\n\n\n\n\n\n\nsource\n\n\ncreate_barplot\n\n create_barplot (df:pandas.core.frame.DataFrame, x:str, y:str,\n                 cmap:str='flare')\n\nCreates an horizontal barplot of the data in the dataframe\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe input dataset\n\n\nx\nstr\n\nthe column with the numerical variable to be plotted\n\n\ny\nstr\n\nthe column with the name associated to each value\n\n\ncmap\nstr\nflare\nthe color palette to be used\n\n\n\n\ncreate_barplot(interactions, 'count', 'actor')\n\n\n\n\nWe can also extract specific statements associated to just one actor and representing just one verb\n\nsource\n\n\nsubset_actor_verb\n\n subset_actor_verb (df:pandas.core.frame.DataFrame, actor:str, verb:str)\n\nReturns the subset of the original dataframe containing only statements with the specified actor and verb\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nThe dataset containing the xAPI statements (one statement per row)\n\n\nactor\nstr\nThe actor we are interested in\n\n\nverb\nstr\nThe verb we are interested in\n\n\nReturns\nDataFrame\nA dataframe containing only the statements with a specific actor and verb\n\n\n\n\nsubset = subset_actor_verb(statements, \"teacher\", \"Assigned\")\nsubset.head(5)\n\n\n\n\n\n\n\n\ntimestamp\nstored\nactor\nverb\nobject\nresult\n\n\n\n\n316\n2023-03-10 12:04:36.832000+00:00\n2023-03-10T12:04:36.832Z\nteacher\nAssigned\n7.72;iPhone_1\nNaN\n\n\n368\n2023-03-10 12:05:37.368000+00:00\n2023-03-10T12:05:37.368Z\nteacher\nAssigned\n8.15;Android2\nNaN\n\n\n397\n2023-03-10 12:06:24.752000+00:00\n2023-03-10T12:06:24.752Z\nteacher\nAssigned\n7.72;Tablet1\nNaN\n\n\n541\n2023-03-10 12:11:20.420000+00:00\n2023-03-10T12:11:20.420Z\nteacher\nAssigned\n7.45;Tablet_2\nNaN\n\n\n582\n2023-03-10 12:12:12.001000+00:00\n2023-03-10T12:12:12.001Z\nteacher\nAssigned\n7.72;iPad2\nNaN\n\n\n\n\n\n\n\nFrom the subset we could analyse the objects to detect if there are any interesting patterns. In the example, we could extract the values (one is a score, the other the actor to whom it was assigned)\n\nsource\n\n\nsplit_column\n\n split_column (df:pandas.core.frame.DataFrame, col:str, col_names:List,\n               sep:str=';')\n\nSplits the column of the DataFrame into multiple columns, and return a new data\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe dataset containing the xAPI statements (one statement per row)\n\n\ncol\nstr\n\nThe column in the dataset that should be split into multiple columns\n\n\ncol_names\ntyping.List\n\nThe names of the columns created after split\n\n\nsep\nstr\n;\nThe separator between fiels inside the column we want to split\n\n\nReturns\nDataFrame\n\nA dataframe with the content col cplit into several columns\n\n\n\n\ngrades = split_column(subset, 'object', ['score', 'student'])\ngrades.head(5)\n\n\n\n\n\n\n\n\nscore\nstudent\n\n\n\n\n316\n7.72\niPhone_1\n\n\n368\n8.15\nAndroid2\n\n\n397\n7.72\nTablet1\n\n\n541\n7.45\nTablet_2\n\n\n582\n7.72\niPad2\n\n\n\n\n\n\n\n\nsource\n\n\naverage_interactions\n\n average_interactions (df:pandas.core.frame.DataFrame, avg_col:str,\n                       user_col:str='actor')\n\nSimilar to count_interactions, but here creates a new dataframe averaging the statements associated to a specific column\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe dataset containing the xAPI statements (one statement per row)\n\n\navg_col\nstr\n\nThe column on which to compute average\n\n\nuser_col\nstr\nactor\nThe column to groupby (usually actor)\n\n\nReturns\nDataFrame\n\nA new dataframe with the average of the interaction per specific value\n\n\n\n\ngrades[\"score\"] = grades[\"score\"].astype(\"float\")\navg_grades = average_interactions(grades, 'score', 'student')\navg_grades\n\n\n\n\n\n\n\n\nstudent\nscore\n\n\n\n\n2\nAndroid4\n2.726667\n\n\n4\nIpad2\n3.000000\n\n\n6\nTablet1_\n4.000000\n\n\n11\niphone_1\n5.000000\n\n\n10\niPhone_1\n5.035000\n\n\n0\nAndroid1\n6.125000\n\n\n5\nTablet1\n6.860000\n\n\n1\nAndroid2\n7.380000\n\n\n8\niPad1\n7.500000\n\n\n3\nIpad1\n7.660000\n\n\n9\niPad2\n7.720000\n\n\n7\nTablet_2\n8.016667\n\n\n\n\n\n\n\n\ncreate_barplot(avg_grades, 'score', 'student', cmap='mako')"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "xapi_analysis",
    "section": "",
    "text": "This library provides the functions necessary to import and process xAPI statements, whether they are provided as JSON or csv files.\nThe documentation of the library provides tests and examples for the function, and it can be used as the starting point for analysing xAPI statements datasets."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "xapi_analysis",
    "section": "Install",
    "text": "Install\npip install git+https://github.com/stocastico/xapi_analysis.git"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "xapi_analysis",
    "section": "How to use",
    "text": "How to use\nAfter installing, import the modules in your Python code using the following calls\n\nfrom xapi_analysis.input_json import *\nfrom xapi_analysis.input_csv import *\n\nAnd from there you can use all the functions defined there.\n\nExample\nAs an example, let’s just open a toy dataset of xAPI statements and run some functions on it\n\ncsv_file = '../example_statements_4.csv'\nstatements = import_csv(csv_file, index_col=0, delimiter=',')\nstatements.head(5)\n\n\n\n\n\n\n\n\ntimestamp\nstored\nactor\nverb\nobject\nresult\n\n\n\n\n0\n2023-03-10 11:45:09.638000+00:00\n2023-03-10T11:45:09.638Z\nTeacher\nLogged In\nSalesianos\nNaN\n\n\n1\n2023-03-10 11:52:00.020000+00:00\n2023-03-10T11:52:00.020Z\nPC006\nLogged In\nSalesianos\nNaN\n\n\n2\n2023-03-10 11:52:04.063000+00:00\n2023-03-10T11:52:04.063Z\nPC008\nLogged In\nSalesianos\nNaN\n\n\n3\n2023-03-10 11:52:05.177000+00:00\n2023-03-10T11:52:05.177Z\nTablet1\nLogged In\nSalesianos\n{\"score\":{\"raw\":0}}\n\n\n4\n2023-03-10 11:52:05.679000+00:00\n2023-03-10T11:52:05.679Z\nPC004\nLogged In\nSalesianos\nNaN\n\n\n\n\n\n\n\nProcess and filter the data:\n\nstatements = remove_whitespaces(statements, [\"actor\"])\nstatements = to_lowercase(statements, [\"actor\"])\nstatements = remove_verbs(statements, [\"Logged In\", \"Logged Out\"])\nstatements = remove_actors(statements, [\"android3\"])\nstatements.head(5)\n\n\n\n\n\n\n\n\ntimestamp\nstored\nactor\nverb\nobject\nresult\n\n\n\n\n14\n2023-03-10 11:52:18.277000+00:00\n2023-03-10T11:52:18.277Z\niphone1\nPlaced\nEarth\n{\"score\":{\"raw\":0}}\n\n\n15\n2023-03-10 11:52:18.847000+00:00\n2023-03-10T11:52:18.847Z\niphone1\nSwiped\nLeft\n{\"score\":{\"raw\":0}}\n\n\n18\n2023-03-10 11:52:29.001000+00:00\n2023-03-10T11:52:29.001Z\niphone1\nPlaced\nEarth\n{\"score\":{\"raw\":0}}\n\n\n19\n2023-03-10 11:52:29.094000+00:00\n2023-03-10T11:52:29.094Z\nandroid2\nPlaced\nEarth\n{\"score\":{\"raw\":0}}\n\n\n20\n2023-03-10 11:52:29.194000+00:00\n2023-03-10T11:52:29.194Z\niphone1\nSwiped\nRight\n{\"score\":{\"raw\":0}}\n\n\n\n\n\n\n\nCount the number of statements sent by each actor\n\ninteractions =  count_interactions(statements)\ninteractions\n\n\n\n\n\n\n\n\nactor\ncount\n\n\n\n\n0\npc009\n6\n\n\n1\npc006\n13\n\n\n2\npc008\n19\n\n\n3\npc002\n21\n\n\n4\npc004\n32\n\n\n5\npc007\n42\n\n\n6\npc003\n43\n\n\n7\niphone1\n86\n\n\n8\nipad1\n87\n\n\n9\nandroid4\n106\n\n\n10\nteacher\n112\n\n\n11\nandroid1\n119\n\n\n12\ntablet1\n133\n\n\n13\nipad2\n140\n\n\n14\ntablet2\n145\n\n\n15\nandroid2\n147\n\n\n\n\n\n\n\n\ncreate_barplot(interactions, 'count', 'actor', cmap='flare')"
  }
]